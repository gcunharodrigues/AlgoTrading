{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from funcoes_preco import organize_data, get_efficiency_ratio, zigzag\n",
    "from datetime import datetime, timedelta\n",
    "from bisect import bisect_right\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_dir = 'C:/Users/guicr/AppData/Roaming/MetaQuotes/Terminal/'\\\n",
    "#             'D0E8209F77C8CF37AD8BF550E51FF075/MQL5/Files/'\n",
    "symbol = 'PETR4'\n",
    "timeframe = 'M5'\n",
    "strategy_name = f'mr_zigzag_cci_er_uniquetf_strategy_{symbol}_{timeframe}'\n",
    "file = f'data/{symbol}_{timeframe}.csv'\n",
    "# start = datetime(2017, 1, 1).timestamp()\n",
    "# end = datetime(2020, 12, 31).timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gravando dados recebidos em um dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = organize_data(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enviando os dados para dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copiando os dataframes para uma variável de manipulação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2021, 12, 21)\n",
    "end = datetime(2021, 12, 31)\n",
    "eqty_table = symbol_data.loc[(symbol_data['Date'] >= start) \n",
    "            & (symbol_data['Date'] <= end)].copy()\n",
    "eqty_table.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando o retorno barra a barra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_change = eqty_table['Close'].pct_change()\n",
    "eqty_table['Percent Change'] = pct_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O trigger será um CCI calculado dinamicamente com base no comprimento \n",
    "# de onda gerado pelo ZigZag. Topo menos Topo e vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um filter também será um indicador calculado dinamicamente com base. \n",
    "# Este filter é o Efficiency Ratio.\n",
    "\n",
    "# Cálculo do ZigZag\n",
    "zigzag_data = zigzag(eqty_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqty_table['ZigZag'] = zigzag_data['zigzag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificando os topos e fundos, a amplitude do movimento e o comprimento\n",
    "do movimento (Analogias utilizando ondas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_df = pd.DataFrame()\n",
    "aux_df['zigzag'] = eqty_table['ZigZag'].copy()\n",
    "aux_df['zigzag'] = aux_df[aux_df['zigzag'] != 0]\n",
    "aux_df['index'] = aux_df.index\n",
    "aux_df.dropna(inplace=True)\n",
    "aux_df_diff = aux_df.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqty_table['Amplitude'] = np.zeros(len(eqty_table))\n",
    "eqty_table['Comprimento'] = np.zeros(len(eqty_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in aux_df_diff.index:\n",
    "    eqty_table.loc[row, 'Amplitude'] = aux_df_diff.loc[row, 'zigzag']\n",
    "    eqty_table.loc[row, 'Comprimento'] = aux_df_diff.loc[row, 'index']\n",
    "    \n",
    "top_bottom = []\n",
    "for row in eqty_table.index:\n",
    "    if eqty_table.loc[row, 'Amplitude'] == 0 or np.isnan(eqty_table.loc[row, 'Amplitude']):\n",
    "        top_bottom.append(None)\n",
    "    elif eqty_table.loc[row, 'Amplitude'] < 0:\n",
    "        top_bottom.append('bottom')\n",
    "    elif eqty_table.loc[row, 'Amplitude'] > 0:\n",
    "        top_bottom.append('top')\n",
    "        \n",
    "eqty_table['Top_Bottom'] = top_bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo o Efficiency Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo do ER é dinâmico utilizando o comprimento de onda gerado pelo ZigZag.\n",
    "# Este cálculo é feito alterando dinamicamente o período do ER.\n",
    "close = eqty_table['Close'].copy()\n",
    "close_er = get_efficiency_ratio(close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparação do Dataframe para receber as informações de trade.\n",
    "Integração entre o Timeframe maior com o menor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mudar o tipo da coluna 'Date' para datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqty_table['Date'] = pd.to_datetime(eqty_table['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuração dos sinais de compra e venda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_position = False\n",
    "position = []\n",
    "pos_type = []\n",
    "\n",
    "\n",
    "shift = 0\n",
    "er_1 = 0.1\n",
    "er_2 = 1\n",
    "\n",
    "d_top = 0\n",
    "d_bottom = 0\n",
    "\n",
    "for row in eqty_table[tf_1].index:\n",
    "    \n",
    "    if row < cci_period:\n",
    "        continue\n",
    "    \n",
    "    # # Verificação de Topo Duplo ou Fundo Duplo\n",
    "    # if d_bottom == 0:\n",
    "    #     if eqty_table[tf_1].loc[row-1, 'CCI'] < -100 and \\\n",
    "    #         eqty_table[tf_1].loc[row, 'CCI'] > -100:\n",
    "    #             d_bottom += 1\n",
    "                \n",
    "    # if d_top == 0:\n",
    "    #     if eqty_table[tf_1].loc[row-1, 'CCI'] > 100 and \\\n",
    "    #         eqty_table[tf_1].loc[row, 'CCI'] < 100:\n",
    "    #             d_top += 1\n",
    "                \n",
    "    # if d_bottom > 0 and eqty_table[tf_1].loc[row, 'CCI'] > 0:\n",
    "    #     d_bottom = 0\n",
    "    \n",
    "    # if d_top > 0 and eqty_table[tf_1].loc[row, 'CCI'] < 0:\n",
    "    #     d_top = 0                \n",
    "\n",
    "    # Sinal entrada de Compra\n",
    "    elif not open_position and \\\n",
    "        d_bottom == 0 and \\\n",
    "        eqty_table[tf_1].loc[row-1, 'CCI'] < 0 and \\\n",
    "        eqty_table[tf_1].loc[row, 'CCI'] > 0 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-shift, \n",
    "                                'Skewness'] < -0.5 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-shift, \n",
    "                                'Skewness'] > -1 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-shift,\n",
    "                              'Efficiency Ratio'] < er_1 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-1-shift,\n",
    "                              'Efficiency Ratio'] < er_2:\n",
    "            open_position = True\n",
    "            pos_type = 'Buy'\n",
    "            # Revisar como fazer arredondamento de 5 em 5\n",
    "            stop_loss = eqty_table[tf_1].loc[row, 'Close'] - \\\n",
    "                (5 * np.ceil((2 * eqty_table[tf_1].loc[row, 'Standard Deviation']) / 5))\n",
    "            std = eqty_table[tf_1].loc[row, 'Standard Deviation']\n",
    "            position.append([row, pos_type, eqty_table[tf_1].loc[row+1, 'Open'],\n",
    "                             std, stop_loss])\n",
    "    \n",
    "    # Sinal de Saída da Compra\n",
    "    elif open_position and \\\n",
    "        pos_type == 'Buy' and \\\n",
    "        eqty_table[tf_1].loc[row-1, 'CCI'] < 100 and \\\n",
    "        eqty_table[tf_1].loc[row, 'CCI'] > 100:\n",
    "            open_position = False\n",
    "            pos_type = 'Exit Buy'\n",
    "            position.append([row, pos_type, eqty_table[tf_1].loc[row, 'Close'],\n",
    "                             np.nan, np.nan])\n",
    "    \n",
    "    elif open_position and \\\n",
    "        pos_type == 'Buy' and \\\n",
    "        eqty_table[tf_1].loc[row-1, 'CCI'] > -100 and \\\n",
    "        eqty_table[tf_1].loc[row, 'CCI'] < -100:\n",
    "            open_position = False\n",
    "            pos_type = 'Exit Buy'\n",
    "            position.append([row, pos_type, eqty_table[tf_1].loc[row, 'Close'],\n",
    "                             np.nan, np.nan])\n",
    "    \n",
    "    elif open_position and \\\n",
    "        eqty_table[tf_1].loc[row, 'Low'] <= stop_loss:\n",
    "            open_position = False\n",
    "            pos_type = 'Exit Buy'\n",
    "            position.append([row, pos_type, stop_loss, np.nan, np.nan])\n",
    "            \n",
    "    # Sinal entrada de Venda\n",
    "    elif not open_position and \\\n",
    "        d_top == 0 and \\\n",
    "        eqty_table[tf_1].loc[row-1, 'CCI'] > 0 and \\\n",
    "        eqty_table[tf_1].loc[row, 'CCI'] < 0 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-shift, \n",
    "                                'Skewness'] > 0.5 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-shift, \n",
    "                                'Skewness'] < 1 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-shift,\n",
    "                              'Efficiency Ratio'] < er_1 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-1-shift,\n",
    "                              'Efficiency Ratio'] < er_2:\n",
    "            open_position = True\n",
    "            pos_type = 'Sell'\n",
    "            stop_loss = eqty_table[tf_1].loc[row, 'Close'] + \\\n",
    "                (5 * np.ceil((2 * eqty_table[tf_1].loc[row, 'Standard Deviation']) / 5))\n",
    "            std = eqty_table[tf_1].loc[row, 'Standard Deviation']\n",
    "            position.append([row, pos_type, eqty_table[tf_1].loc[row+1, 'Open'],\n",
    "                             std, stop_loss])\n",
    "            \n",
    "    # Sinal de Saída da Venda\n",
    "    elif open_position and \\\n",
    "        pos_type == 'Sell' and \\\n",
    "        eqty_table[tf_1].loc[row-1, 'CCI'] > -100 and \\\n",
    "        eqty_table[tf_1].loc[row, 'CCI'] < -100:\n",
    "            open_position = False\n",
    "            pos_type = 'Exit Sell'\n",
    "            position.append([row, pos_type, eqty_table[tf_1].loc[row, 'Close'],\n",
    "                             np.nan, np.nan])\n",
    "    \n",
    "    elif open_position and \\\n",
    "        pos_type == 'Sell' and \\\n",
    "        eqty_table[tf_1].loc[row-1, 'CCI'] < 100 and \\\n",
    "        eqty_table[tf_1].loc[row, 'CCI'] > 100:\n",
    "            open_position = False\n",
    "            pos_type = 'Exit Sell'\n",
    "            position.append([row, pos_type, eqty_table[tf_1].loc[row, 'Close'],\n",
    "                             np.nan, np.nan])\n",
    "            \n",
    "    elif open_position and \\\n",
    "        eqty_table[tf_1].loc[row, 'High'] >= stop_loss:\n",
    "            open_position = False\n",
    "            pos_type = 'Exit Sell'\n",
    "            position.append([row, pos_type, stop_loss, np.nan, np.nan])\n",
    "    \n",
    "    # Cálculo da Máxima Exposição Favorável e Máxima Exposição Desfavorável\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqty_table[tf_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo do retorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(position, columns=['Index', 'Position Type', 'Position', \n",
    "                                     'Standard Deviation', 'Stop Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.iloc[::2] \n",
    "df2.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.iloc[1::2]\n",
    "df3.reset_index(inplace=True, drop=True)\n",
    "df3.rename(columns={'Position': 'Position Exit', \n",
    "                    'Position Type': 'Position Type Exit',\n",
    "                    'Standard Deviation': 'Standard Deviation Exit',\n",
    "                    'Stop Loss': 'Stop Loss Exit'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df2, df3], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "for row in df.index:\n",
    "    if df.loc[row, 'Position Type'] == 'Buy':\n",
    "        points = np.append(points, df.loc[row, 'Position Exit'] - df.loc[row, 'Position'])\n",
    "    else:\n",
    "        points = np.append(points, [df.loc[row, 'Position'] - df.loc[row, 'Position Exit']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = df['Standard Deviation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = points / stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estatísticas do retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_value = 0\n",
    "win_stk = 0\n",
    "loss_stk = 0\n",
    "pos_stk = 0\n",
    "neg_stk = 0\n",
    "max_sum_r = 0\n",
    "sum_ant = 0\n",
    "dd = []\n",
    "for value in r:\n",
    "    if value >= 0 and last_value >= 0:\n",
    "        win_stk += 1\n",
    "        if win_stk > pos_stk:\n",
    "            pos_stk = win_stk\n",
    "    elif value < 0 and last_value <= 0:\n",
    "        loss_stk += 1\n",
    "        if loss_stk > neg_stk:\n",
    "            neg_stk = loss_stk\n",
    "    else:\n",
    "        win_stk = 1\n",
    "        loss_stk = 1\n",
    "    \n",
    "    last_value = value\n",
    "    \n",
    "    sum_r = sum_ant + value\n",
    "    sum_ant = sum_r\n",
    "    if max_sum_r < sum_r:\n",
    "        max_sum_r = sum_r\n",
    "    dd.append(sum_r - max_sum_r)\n",
    "    \n",
    "print(pos_stk)\n",
    "print(neg_stk)\n",
    "print(abs(min(dd)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = stats.zscore(r)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_r = r[abs_z_scores < 3]\n",
    "stats.describe(filtered_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(filtered_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_data = {\n",
    "    'tf_1': tf_1,\n",
    "    'tf_2': tf_2,\n",
    "    'cci_period': cci_period,\n",
    "    'std_dev_period': std_dev_period,\n",
    "    'er_period': er_period,\n",
    "    'skew_period': skew_period,\n",
    "    'shift': shift,\n",
    "    'er_1': er_1,\n",
    "    'er_2': er_2,\n",
    "}\n",
    "filename = f'{strategy_name}_specs.txt'\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(str(strategy_data))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
