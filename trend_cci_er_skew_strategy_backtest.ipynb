{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from funcoes_preco import organize_data, get_efficiency_ratio, get_stats\n",
    "import dwx_query\n",
    "from datetime import datetime, timedelta\n",
    "from bisect import bisect_right\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_dir = 'C:/Users/guicr/AppData/Roaming/MetaQuotes/Terminal/'\\\n",
    "#             'D0E8209F77C8CF37AD8BF550E51FF075/MQL5/Files/'\n",
    "symbol = 'PETR4'\n",
    "tf_1 = 'M5'\n",
    "tf_2 = 'M5'\n",
    "timeframes = [tf_1, tf_2]\n",
    "strategy_name = f'cci_er_skew_strategy_{symbol}_{tf_1}_{tf_2}'\n",
    "# start = datetime(2017, 1, 1).timestamp()\n",
    "# end = datetime(2020, 12, 31).timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gravando dados recebidos em um dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {timeframe: organize_data(f'data/{symbol}_{timeframe}.csv') \n",
    "        for timeframe in timeframes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enviando os dados para dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copiando os dataframes para uma variável de manipulação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2015, 1, 1)\n",
    "end = datetime(2021, 12, 31)\n",
    "eqty_table = {timeframe: \n",
    "    symbol_data[timeframe].loc[(symbol_data[timeframe]['Date'] >= start) \n",
    "                               & (symbol_data[timeframe]['Date'] <= end)].copy()\n",
    "    for timeframe in timeframes}\n",
    "for timeframe in timeframes:\n",
    "    eqty_table[timeframe].reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando o retorno barra a barra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_change = {timeframe: eqty_table[timeframe]['Close'].pct_change() \n",
    "              for timeframe in timeframes}\n",
    "for timeframe in timeframes:\n",
    "    eqty_table[timeframe]['Percent Change'] = pct_change[timeframe]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cci_period = 20\n",
    "cci = talib.CCI(eqty_table[tf_1]['High'], eqty_table[tf_1]['Low'], \n",
    "                eqty_table[tf_1]['Close'], timeperiod=cci_period)\n",
    "eqty_table[tf_1]['CCI'] = cci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev_period = 15\n",
    "std_dev = get_stats(eqty_table[tf_1]['Close'], std_dev_period)['std']\n",
    "eqty_table[tf_1]['Standard Deviation'] = std_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_period = 8\n",
    "efficiency_ratio = get_efficiency_ratio(eqty_table[tf_2]['Close'], \n",
    "                                        timeperiod=er_period)\n",
    "eqty_table[tf_2]['Efficiency Ratio'] = efficiency_ratio['efficiency_ratio']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_period = 15\n",
    "skewness = get_stats(eqty_table[tf_2]['Close'], skew_period)['skewness']\n",
    "eqty_table[tf_2]['Skewness'] = skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparação do Dataframe para receber as informações de trade.\n",
    "Integração entre o Timeframe maior com o menor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mudar o tipo da coluna 'Date' para datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for timeframe in timeframes:\n",
    "    eqty_table[timeframe]['Date'] = pd.to_datetime(eqty_table[timeframe]['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colocando um marcador para identificar a correspondência entre o Timeframe \n",
    "maior e o menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lwr_timeframe_table = eqty_table[tf_1].copy()\n",
    "hgr_timeframe_table = eqty_table[tf_2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_higher_timeframe = []\n",
    "for row_lwr_timeframe in lwr_timeframe_table.index:\n",
    "    index = bisect_right(hgr_timeframe_table['Date'], \n",
    "                         lwr_timeframe_table.loc[row_lwr_timeframe, 'Date'])\n",
    "    index_higher_timeframe.append(index-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqty_table[tf_1]['Index Higher Timeframe'] = index_higher_timeframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuração dos sinais de compra e venda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_position = False\n",
    "position = []\n",
    "pos_type = []\n",
    "\n",
    "shift = 0\n",
    "er_1 = 0.1\n",
    "er_2 = 1\n",
    "\n",
    "d_top = 0\n",
    "d_bottom = 0\n",
    "\n",
    "for row in eqty_table[tf_1].index:\n",
    "    \n",
    "    if row < cci_period:\n",
    "        continue\n",
    "    \n",
    "    # # Verificação de Topo Duplo ou Fundo Duplo\n",
    "    # if d_bottom == 0:\n",
    "    #     if eqty_table[tf_1].loc[row-1, 'CCI'] < -100 and \\\n",
    "    #         eqty_table[tf_1].loc[row, 'CCI'] > -100:\n",
    "    #             d_bottom += 1\n",
    "                \n",
    "    # if d_top == 0:\n",
    "    #     if eqty_table[tf_1].loc[row-1, 'CCI'] > 100 and \\\n",
    "    #         eqty_table[tf_1].loc[row, 'CCI'] < 100:\n",
    "    #             d_top += 1\n",
    "                \n",
    "    # if d_bottom > 0 and eqty_table[tf_1].loc[row, 'CCI'] > 0:\n",
    "    #     d_bottom = 0\n",
    "    \n",
    "    # if d_top > 0 and eqty_table[tf_1].loc[row, 'CCI'] < 0:\n",
    "    #     d_top = 0                \n",
    "\n",
    "    # Sinal entrada de Compra\n",
    "    elif not open_position and \\\n",
    "        d_bottom == 0 and \\\n",
    "        eqty_table[tf_1].loc[row-1, 'CCI'] < 0 and \\\n",
    "        eqty_table[tf_1].loc[row, 'CCI'] > 0 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-shift, \n",
    "                                'Skewness'] < -0.5 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-shift, \n",
    "                                'Skewness'] > -1 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-shift,\n",
    "                              'Efficiency Ratio'] < er_1 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-1-shift,\n",
    "                              'Efficiency Ratio'] < er_2:\n",
    "            open_position = True\n",
    "            pos_type = 'Buy'\n",
    "            # Revisar como fazer arredondamento de 5 em 5\n",
    "            stop_loss = eqty_table[tf_1].loc[row, 'Close'] - \\\n",
    "                (5 * np.ceil((2 * eqty_table[tf_1].loc[row, 'Standard Deviation']) / 5))\n",
    "            std = eqty_table[tf_1].loc[row, 'Standard Deviation']\n",
    "            position.append([row, pos_type, eqty_table[tf_1].loc[row+1, 'Open'],\n",
    "                             std, stop_loss])\n",
    "    \n",
    "    # Sinal de Saída da Compra\n",
    "    elif open_position and \\\n",
    "        pos_type == 'Buy' and \\\n",
    "        eqty_table[tf_1].loc[row-1, 'CCI'] < 100 and \\\n",
    "        eqty_table[tf_1].loc[row, 'CCI'] > 100:\n",
    "            open_position = False\n",
    "            pos_type = 'Exit Buy'\n",
    "            position.append([row, pos_type, eqty_table[tf_1].loc[row, 'Close'],\n",
    "                             np.nan, np.nan])\n",
    "    \n",
    "    elif open_position and \\\n",
    "        pos_type == 'Buy' and \\\n",
    "        eqty_table[tf_1].loc[row-1, 'CCI'] > -100 and \\\n",
    "        eqty_table[tf_1].loc[row, 'CCI'] < -100:\n",
    "            open_position = False\n",
    "            pos_type = 'Exit Buy'\n",
    "            position.append([row, pos_type, eqty_table[tf_1].loc[row, 'Close'],\n",
    "                             np.nan, np.nan])\n",
    "    \n",
    "    elif open_position and \\\n",
    "        eqty_table[tf_1].loc[row, 'Low'] <= stop_loss:\n",
    "            open_position = False\n",
    "            pos_type = 'Exit Buy'\n",
    "            position.append([row, pos_type, stop_loss, np.nan, np.nan])\n",
    "            \n",
    "    # Sinal entrada de Venda\n",
    "    elif not open_position and \\\n",
    "        d_top == 0 and \\\n",
    "        eqty_table[tf_1].loc[row-1, 'CCI'] > 0 and \\\n",
    "        eqty_table[tf_1].loc[row, 'CCI'] < 0 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-shift, \n",
    "                                'Skewness'] > 0.5 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-shift, \n",
    "                                'Skewness'] < 1 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-shift,\n",
    "                              'Efficiency Ratio'] < er_1 and \\\n",
    "        eqty_table[tf_2].loc[eqty_table[tf_1]['Index Higher Timeframe'][row]-1-shift,\n",
    "                              'Efficiency Ratio'] < er_2:\n",
    "            open_position = True\n",
    "            pos_type = 'Sell'\n",
    "            stop_loss = eqty_table[tf_1].loc[row, 'Close'] + \\\n",
    "                (5 * np.ceil((2 * eqty_table[tf_1].loc[row, 'Standard Deviation']) / 5))\n",
    "            std = eqty_table[tf_1].loc[row, 'Standard Deviation']\n",
    "            position.append([row, pos_type, eqty_table[tf_1].loc[row+1, 'Open'],\n",
    "                             std, stop_loss])\n",
    "            \n",
    "    # Sinal de Saída da Venda\n",
    "    elif open_position and \\\n",
    "        pos_type == 'Sell' and \\\n",
    "        eqty_table[tf_1].loc[row-1, 'CCI'] > -100 and \\\n",
    "        eqty_table[tf_1].loc[row, 'CCI'] < -100:\n",
    "            open_position = False\n",
    "            pos_type = 'Exit Sell'\n",
    "            position.append([row, pos_type, eqty_table[tf_1].loc[row, 'Close'],\n",
    "                             np.nan, np.nan])\n",
    "    \n",
    "    elif open_position and \\\n",
    "        pos_type == 'Sell' and \\\n",
    "        eqty_table[tf_1].loc[row-1, 'CCI'] < 100 and \\\n",
    "        eqty_table[tf_1].loc[row, 'CCI'] > 100:\n",
    "            open_position = False\n",
    "            pos_type = 'Exit Sell'\n",
    "            position.append([row, pos_type, eqty_table[tf_1].loc[row, 'Close'],\n",
    "                             np.nan, np.nan])\n",
    "            \n",
    "    elif open_position and \\\n",
    "        eqty_table[tf_1].loc[row, 'High'] >= stop_loss:\n",
    "            open_position = False\n",
    "            pos_type = 'Exit Sell'\n",
    "            position.append([row, pos_type, stop_loss, np.nan, np.nan])\n",
    "    \n",
    "    # Cálculo da Máxima Exposição Favorável e Máxima Exposição Desfavorável\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqty_table[tf_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo do retorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(position, columns=['Index', 'Position Type', 'Position', \n",
    "                                     'Standard Deviation', 'Stop Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.iloc[::2] \n",
    "df2.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.iloc[1::2]\n",
    "df3.reset_index(inplace=True, drop=True)\n",
    "df3.rename(columns={'Position': 'Position Exit', \n",
    "                    'Position Type': 'Position Type Exit',\n",
    "                    'Standard Deviation': 'Standard Deviation Exit',\n",
    "                    'Stop Loss': 'Stop Loss Exit'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df2, df3], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "for row in df.index:\n",
    "    if df.loc[row, 'Position Type'] == 'Buy':\n",
    "        points = np.append(points, df.loc[row, 'Position Exit'] - df.loc[row, 'Position'])\n",
    "    else:\n",
    "        points = np.append(points, [df.loc[row, 'Position'] - df.loc[row, 'Position Exit']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = df['Standard Deviation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = points / stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estatísticas do retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_value = 0\n",
    "win_stk = 0\n",
    "loss_stk = 0\n",
    "pos_stk = 0\n",
    "neg_stk = 0\n",
    "max_sum_r = 0\n",
    "sum_ant = 0\n",
    "dd = []\n",
    "for value in r:\n",
    "    if value >= 0 and last_value >= 0:\n",
    "        win_stk += 1\n",
    "        if win_stk > pos_stk:\n",
    "            pos_stk = win_stk\n",
    "    elif value < 0 and last_value <= 0:\n",
    "        loss_stk += 1\n",
    "        if loss_stk > neg_stk:\n",
    "            neg_stk = loss_stk\n",
    "    else:\n",
    "        win_stk = 1\n",
    "        loss_stk = 1\n",
    "    \n",
    "    last_value = value\n",
    "    \n",
    "    sum_r = sum_ant + value\n",
    "    sum_ant = sum_r\n",
    "    if max_sum_r < sum_r:\n",
    "        max_sum_r = sum_r\n",
    "    dd.append(sum_r - max_sum_r)\n",
    "    \n",
    "print(pos_stk)\n",
    "print(neg_stk)\n",
    "print(abs(min(dd)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = stats.zscore(r)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_r = r[abs_z_scores < 3]\n",
    "stats.describe(filtered_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(filtered_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_data = {\n",
    "    'tf_1': tf_1,\n",
    "    'tf_2': tf_2,\n",
    "    'cci_period': cci_period,\n",
    "    'std_dev_period': std_dev_period,\n",
    "    'er_period': er_period,\n",
    "    'skew_period': skew_period,\n",
    "    'shift': shift,\n",
    "    'er_1': er_1,\n",
    "    'er_2': er_2,\n",
    "}\n",
    "filename = f'{strategy_name}_specs.txt'\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(str(strategy_data))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
